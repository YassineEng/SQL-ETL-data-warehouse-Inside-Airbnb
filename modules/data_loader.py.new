import os
import glob
import pyodbc
import gzip
import tempfile
import pandas as pd
from config.database_config import DatabaseConfig
from config.settings import Config
from modules.data_validator import DataValidator

class AirbnbDataLoader:
    def __init__(self, config: Config):
        self.config = config
        self.db_config = DatabaseConfig()
        self.data_validator = DataValidator()
        self.consecutive_errors = 0

    def load_to_warehouse(self):
        print("üì• Starting SQL Server Data Warehouse Loading...")
        cleaned_files = glob.glob(os.path.join(self.config.CLEANED_DATA_FOLDER, "*.csv.gz"))
        if not cleaned_files:
            print("‚ùå No cleaned data found. Please run Data Cleaning first (Option 2).")
            return

        if not self.db_config.test_connection():
            print("‚ùå Cannot connect to SQL Server.")
            return

        self.db_config.create_database()
        conn = self.db_config.create_connection(database='AirbnbDataWarehouse')
        try:
            self._execute_sql_file(conn, 'sql/data/00_prepare_tables.sql')
            self._execute_schema_scripts(conn)
            self._load_data_with_dynamic_paths(conn)
            self._execute_view_scripts(conn)
            self._show_database_statistics(conn)
            print("\n‚úÖ SQL Data Warehouse loading completed!")
        except Exception as e:
            print(f"‚ùå Error during data loading: {e}")
        finally:
            conn.close()

    def _load_data_with_dynamic_paths(self, conn):
        listings_files = glob.glob(os.path.join(self.config.CLEANED_DATA_FOLDER, "*listings*.csv.gz"))
        calendar_files = glob.glob(os.path.join(self.config.CLEANED_DATA_FOLDER, "*calendar*.csv.gz"))
        reviews_files = glob.glob(os.path.join(self.config.CLEANED_DATA_FOLDER, "*reviews*.csv.gz"))

        if not listings_files:
            print("‚ùå No cleaned listings files found")
            return

        for file_path in listings_files:
            self._load_listings_data(conn, file_path)

        self._execute_sql_file(conn, 'sql/data/02_load_hosts.sql')
        self._execute_sql_file(conn, 'sql/data/03_load_dates.sql')

        for file_path in calendar_files:
            self._load_calendar_data(conn, file_path)

        for file_path in reviews_files:
            self._load_reviews_data(conn, file_path)

    def _load_listings_data(self, conn, file_path: str):
        print(f"   ‚Ü≥ Loading listings file: {os.path.basename(file_path)}")
        temp_file_path = None
        cursor = conn.cursor()

        try:
            df = pd.read_csv(gzip.open(file_path, 'rt', encoding='utf-8'), sep='|', engine='python')

            expected_cols = ['id','host_id','host_name','host_city','host_country','property_country','property_city','property_neighbourhood','price','number_of_reviews','review_scores_rating','calculated_host_listings_count','is_local_host']
            for c in expected_cols:
                if c not in df.columns:
                    df[c] = None

            def sanitize_str(val, maxlen=4000):
                if pd.isna(val):
                    return None
                s = str(val).strip()
                return s[:maxlen] if s else None

            def sanitize_numstr(val):
                if pd.isna(val):
                    return None
                s = str(val).strip()
                s = s.replace(',', '')
                if s.endswith('.0'):
                    s = s[:-2]
                return s if s != '' else None

            def sanitize_price(val):
                if pd.isna(val):
                    return None
                s = str(val).strip()
                return s.replace('$','').replace(',','')

            def norm_bool(v):
                if pd.isna(v):
                    return None
                sv = str(v).strip()
                return 'True' if sv.lower() in ('true','1','t','y','yes') else 'False' if sv.lower() in ('false','0','f','n','no') else sv

            rows = []
            for _, r in df.iterrows():
                rows.append((
                    sanitize_str(r.get('id')),
                    sanitize_numstr(r.get('host_id')),
                    sanitize_str(r.get('host_name'), 255),
                    sanitize_str(r.get('host_city'), 255),
                    sanitize_str(r.get('host_country'), 100),
                    sanitize_str(r.get('property_country'), 100),
                    sanitize_str(r.get('property_city'), 255),
                    sanitize_str(r.get('property_neighbourhood'), 255),
                    sanitize_price(r.get('price')),
                    sanitize_numstr(r.get('number_of_reviews')),
                    sanitize_numstr(r.get('review_scores_rating')),
                    sanitize_numstr(r.get('calculated_host_listings_count')),
                    norm_bool(r.get('is_local_host'))
                ))

            try:
                cursor.execute("TRUNCATE TABLE dim_listings_staging;")
                conn.commit()
            except Exception:
                pass

            insert_staging_sql = (
                "INSERT INTO dim_listings_staging (listing_id, host_id, host_name, host_city, host_country, property_country, property_city, property_neighbourhood, price, number_of_reviews, review_scores_rating, calculated_host_listings_count, is_local_host) "
                "VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)"
            )

            cursor.fast_executemany = True
            batch_size = 500
            staging_inserted = 0
            for i in range(0, len(rows), batch_size):
                batch = rows[i:i+batch_size]
                try:
                    cursor.executemany(insert_staging_sql, batch)
                    conn.commit()
                    staging_inserted += len(batch)
                except Exception as be:
                    print(f"   ‚ö†Ô∏è Staging batch insert failed: {be}")
                    for j, single in enumerate(batch):
                        try:
                            cursor.execute(insert_staging_sql, single)
                            conn.commit()
                            staging_inserted += 1
                        except Exception as se:
                            # write skipped rows to a small CSV for inspection
                            errlog = os.path.join(self.config.LOGS_DIR, 'listings_skipped_rows.csv')
                            with open(errlog, 'a', encoding='utf-8') as ef:
                                ef.write(','.join([str(x) if x is not None else '' for x in single]) + '\n')

            print(f"   INFO: staged {staging_inserted} rows into dim_listings_staging")

            move_sql = '''
BEGIN TRY
    BEGIN TRANSACTION;

    INSERT INTO dim_listings (
        listing_id, host_id, host_name, host_city, host_country,
        property_country, property_city, property_neighbourhood,
        price, number_of_reviews, review_scores_rating, calculated_host_listings_count, is_local_host
    )
    SELECT
        TRY_CAST(listing_id AS BIGINT) AS listing_id,
        TRY_CAST(host_id AS BIGINT) AS host_id,
        host_name,
        host_city,
        host_country,
        property_country,
        property_city,
        property_neighbourhood,
        TRY_CAST(REPLACE(REPLACE(price, '$', ''), ',', '') AS DECIMAL(10,2)) AS price,
        TRY_CAST(number_of_reviews AS BIGINT) AS number_of_reviews,
        TRY_CAST(review_scores_rating AS DECIMAL(3,2)) AS review_scores_rating,
        TRY_CAST(calculated_host_listings_count AS BIGINT) AS calculated_host_listings_count,
        CASE WHEN is_local_host = 'True' THEN 1 WHEN is_local_host = 'False' THEN 0 ELSE NULL END
    FROM dim_listings_staging
    WHERE TRY_CAST(listing_id AS BIGINT) IS NOT NULL;

    INSERT INTO dim_listing_id_map (listing_id, listing_raw_id, part1, part2, part3)
    SELECT
        TRY_CAST(listing_id AS BIGINT) AS listing_id,
        listing_id AS listing_raw_id,
        LEFT(listing_id, 6) AS part1,
        SUBSTRING(listing_id, 7, 6) AS part2,
        SUBSTRING(listing_id, 13, 6) AS part3
    FROM dim_listings_staging
    WHERE TRY_CAST(listing_id AS BIGINT) IS NOT NULL;

    TRUNCATE TABLE dim_listings_staging;

    COMMIT TRANSACTION;
END TRY
BEGIN CATCH
    ROLLBACK TRANSACTION;
    THROW;
END CATCH
'''

            cursor.execute("SELECT COUNT(*) FROM dim_listings")
            initial_rows = cursor.fetchone()[0]

            try:
                cursor.execute(move_sql)
                conn.commit()
            except Exception as e:
                print(f"   ‚ùå Error moving staging -> dim_listings: {e}")
                conn.rollback()
                return

            cursor.execute("SELECT COUNT(*) FROM dim_listings")
            final_rows = cursor.fetchone()[0]
            added = final_rows - initial_rows
            print(f"   ‚úÖ Loaded: {os.path.basename(file_path)} - Listings added: {added:,}")

        except Exception as e:
            print(f"   ‚ùå Error processing file {file_path}: {e}")
            self.consecutive_errors += 1

    def _load_calendar_data(self, conn, file_path: str):
        temp_file_path = None
        try:
            with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.csv', encoding='utf-8', newline='') as temp_csv_file:
                temp_file_path = temp_csv_file.name
                df = pd.read_csv(gzip.open(file_path, 'rt', encoding='utf-8'), sep='|', engine='python')
                df.to_csv(temp_csv_file, sep='|', index=False, lineterminator='\n')
            self.data_validator.validate_and_fix_calendar_data(temp_file_path)

            with open('sql/data/04_load_calendar.sql', 'r', encoding='utf-8') as f:
                sql_script = f.read()
            sql_script = sql_script.replace('{{CALENDAR_FILE_PATH}}', temp_file_path.replace('\\', '/'))

            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM fact_calendar")
            initial_rows = cursor.fetchone()[0]
            cursor.execute(sql_script)
            conn.commit()
            cursor.execute("SELECT COUNT(*) FROM fact_calendar")
            final_rows = cursor.fetchone()[0]
            print(f"   ‚úÖ Loaded: {os.path.basename(file_path)} - Calendar records added: {final_rows - initial_rows:,}")

        finally:
            if temp_file_path and os.path.exists(temp_file_path):
                os.remove(temp_file_path)

    def _load_reviews_data(self, conn, file_path: str):
        temp_file_path = None
        try:
            temp_file = tempfile.NamedTemporaryFile(mode='wb', delete=False, suffix='.csv')
            temp_file_path = temp_file.name
            with gzip.open(file_path, 'rb') as f_in:
                for line in f_in:
                    temp_file.write(line)
            temp_file.close()

            with open('sql/data/05_load_reviews.sql', 'r', encoding='utf-8') as f:
                sql_script = f.read()
            sql_script = sql_script.replace('{{REVIEWS_FILE_PATH}}', temp_file_path.replace('\\', '\\\\'))

            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM fact_reviews")
            initial_rows = cursor.fetchone()[0]
            cursor.execute(sql_script)
            conn.commit()
            cursor.execute("SELECT COUNT(*) FROM fact_reviews")
            final_rows = cursor.fetchone()[0]
            print(f"   ‚úÖ Loaded: {os.path.basename(file_path)} - Reviews added: {final_rows - initial_rows:,}")

        except Exception as e:
            print(f"   ‚ùå Error loading reviews: {e}")
            conn.rollback()
        finally:
            if temp_file_path and os.path.exists(temp_file_path):
                os.remove(temp_file_path)

    def _execute_schema_scripts(self, conn):
        schema_files = ['sql/schema/02_create_tables.sql']
        for s in schema_files:
            self._execute_sql_file(conn, s)

    def _execute_view_scripts(self, conn):
        self._execute_sql_file(conn, 'sql/schema/03_create_views.sql')

    def _execute_sql_file(self, conn, script_path: str):
        if not os.path.exists(script_path):
            print(f"   ‚ö†Ô∏è  SQL script not found: {script_path}")
            return
        try:
            with open(script_path, 'r', encoding='utf-8') as f:
                sql_script = f.read()
            cursor = conn.cursor()
            cursor.execute(sql_script)
            conn.commit()
            print(f"   ‚úÖ Executed: {os.path.basename(script_path)}")
        except Exception as e:
            print(f"   ‚ùå Error executing {script_path}: {e}")
            conn.rollback()

    def _show_database_statistics(self, conn):
        try:
            cursor = conn.cursor()
            tables = ['dim_listings','dim_hosts','dim_dates','fact_calendar','fact_reviews']
            for t in tables:
                cursor.execute(f"SELECT COUNT(*) FROM {t}")
                print(f"{t}: {cursor.fetchone()[0]}")
        except Exception as e:
            print(f"Error showing stats: {e}")
